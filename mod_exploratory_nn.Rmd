---
title: "LC_nn_exploratory"
author: "Tim Szewczyk"
date: "8/16/2017"
output: html_document
---

```{r setup, include=FALSE}
library(sevcheck)
p_load("tidyverse", "magrittr", "forcats", "neuralnet", "RSNNS")
source("code/LC_fun.R"); theme_set(theme_bw())
```



```{r readData, message=FALSE}
grdSz <- "01_1a"
blockSize <- 10  # block = (blockSize x blockSize) grid cells

# cell-block reference tibble
cb.i <- read_csv(paste0("data/roads_", grdSz, ".csv")) %>% 
  mutate(CellRow=1:n_distinct(top) %>% rep(n_distinct(left)),
         CellCol=1:n_distinct(left) %>% rep(each=n_distinct(top))) %>%
  filter((CellRow <= max((CellRow %/% blockSize) * blockSize)) &
           (CellCol <= max((CellCol %/% blockSize) * blockSize))) %>%
  mutate(BlockRow=((CellRow-1)%/%blockSize)+1, 
         BlockCol=((CellCol-1)%/%blockSize)+1,
         BlockID=paste(BlockCol, BlockRow) %>% factor %>% as.numeric) %>%
  select(c(CellID, CellRow, CellCol, BlockID, BlockRow, BlockCol, left, top))

# covariates summarized to blocks
pop00 <- read_csv(paste0("data/pop00_", grdSz, ".csv")) %>% 
  rename(CellID=category) %>% 
  add_blocks(cb.i=cb.i) %>% summarise(popTot=log(sum(sum)+0.001))
hous00 <- read_csv(paste0("data/housing00_", grdSz, ".csv")) %>% 
  rename(CellID=category) %>% 
  add_blocks(cb.i=cb.i) %>% summarise(secHome=log(sum(sum)+0.001))
rdLen <- read_csv(paste0("data/roads_", grdSz, ".csv")) %>% 
  add_blocks(cb.i=cb.i) %>% summarise(rdLen=log(sum(roadLen)+0.001)) 
clim <- read_csv(paste0("data/clim_", grdSz, ".csv")) %>% 
  add_blocks(cb.i=cb.i) %>% 
  summarise(b1=mean(bio1_mean), b7=mean(bio7_mean), b12=mean(bio12_mean))
topo <- read_csv(paste0("data/topo_", grdSz, ".csv")) %>% 
  add_blocks(cb.i=cb.i) %>% 
  summarise(el=mean(el_mean), rugg=mean(rugg_mean))
pWP <- read_csv(paste0("data/pWP_", grdSz, ".csv")) %>% 
  rename(CellID=category) %>%
  add_blocks(cb.i=cb.i) %>% summarise(mnWP=mean(mean)/100)

# land cover summarized to blocks
grnt <- read_csv(paste0("data/out_", grdSz, "_grnt.csv")) %>% 
  mutate(CellID=1:nrow(.)) %>% add_blocks(cb.i=cb.i) %>% 
  summarise(Dev=sum(V1)/n(), Oth=sum(V2)/n(), Hwd=sum(V3)/n(), 
            WP=sum(V4)/n(), Evg=sum(V5)/n(), Mxd=sum(V6)/n()) %>%
  select(-BlockID) %>% as.matrix
nlcd <- read_csv(paste0("data/out_",grdSz,"_nlcd.csv"))  %>% 
  mutate(CellID=1:nrow(.)) %>% add_blocks(cb.i=cb.i) %>% 
  summarise(Dev=sum(V1)/n(), Oth=sum(V2)/n(), Hwd=sum(V3)/n(), 
            Evg=sum(V4)/n(), Mxd=sum(V5)/n()) %>%
  select(-BlockID) %>% as.matrix
```


```{r modelSetup}
d <- rstan::read_rdump("../null_dir/lc/data/all/TopoClimCens.Rdump")
Yd <- tibble(d1=c(scale(grnt[,1]-nlcd[,1])),
             d2=c(scale(grnt[,2]-nlcd[,2])),
             d3=c(scale(grnt[,3]-nlcd[,3])),
             d4=c(scale((grnt[,4] + grnt[,5])-nlcd[,4])),
             nuWP=c(scale((grnt[,4]+0.0001)/(grnt[,4] + grnt[,5] + 0.0001))),
             valWP=c(scale(pWP$mnWP)),
             rdLen=c(scale(rdLen$rdLen)),
             pop00=c(scale(pop00$popTot)),
             hous00=c(scale(hous00$secHome)),
             tmean=c(scale(clim$b1)),
             tseas=c(scale(clim$b7)),
             precip=c(scale(clim$b12)),
             el=c(scale(topo$el)),
             rugg=c(scale(topo$rugg)))
cor(Yd)
```


```{r nn.rsnns}
##########
# testing with GRANIT ~ NLCD
##########
data_df <- read_csv("../GIS/USDA/lc_cl_tp_rd_wp.csv") %>%
  full_join((read_csv("../GIS/USDA/cn.csv", 
                      col_types=list(col_double(),
                                     col_double(),
                                     col_integer(),
                                     col_double(),
                                     col_double())) %>%
               # sum pop & 2nd home density within each cell
               group_by(CellID) %>%
               summarise(pop=sum(part_pop), hms=sum(part_hms)))) %>%
  # remove small number of edge cells with no climate data
  filter(!is.na(bio1_mean)) 

# set GRANIT columns to NA if no data
no_nhlc <- with(data_df, which(nhlc1_mean == 0 & nhlc2_mean == 0 &
                                 nhlc3_mean == 0 & nhlc4_mean == 0 &
                                 nhlc5_mean == 0 & nhlc6_mean == 0))
data_df[no_nhlc, 8:13] <- NA

# identify cells with/without GRANIT, then set cell IDs
data_df %<>% mutate(Set=is.na(nhlc1_mean)) %>%
  arrange(Set, left, top) %>%
  mutate(CellID=row_number())

# set cells with no census data (i.e., inland bodies of water) to 0 
no_cn <- which(is.na(data_df$pop))
data_df[no_cn, 22:23] <- 0 
nFit <- sum(!data_df$Set)

X <- as.data.frame(scale(data_df[,c(14:18, 1:2, 4:7, 19:23)]))
X.train <- X[1:nFit,]
X.test <- X[(nFit+1):nrow(X),]


Y <- as.data.frame(scale(data_df[1:nFit, 8:13]))

# index <- sample(1:nrow(nlcd), round(0.75*nrow(nlcd)))
# X <- data.frame(NLCD.1=nlcd[,1],
#                 NLCD.2=nlcd[,2],
#                 NLCD.3=nlcd[,3],
#                 NLCD.4=nlcd[,4],
#                 NLCD.5=nlcd[,5],
#                 valWP=pWP$mnWP,
#                 rdLen=rdLen$rdLen,
#                 pop00=pop00$popTot,
#                 hous00=hous00$secHome,
#                 tmean=clim$b1,
#                 tseas=clim$b7,
#                 precip=clim$b12,
#                 el=topo$el,
#                 rugg=topo$rugg,
#                 BlockRow=cb.i$BlockRow[match(pop00$BlockID,
#                                              cb.i$BlockID)],
#                 BlockCol=cb.i$BlockCol[match(pop00$BlockID,
#                                              cb.i$BlockID)])
# X.rng <- list(mins=apply(X, 2, min), maxs=apply(X, 2, max))
# X.scaled <- as.data.frame(scale(X, center=X.rng[[1]], 
#                                    scale=X.rng[[2]]-X.rng[[1]]))
# X.train <- X.scaled[index,]
# X.test <- X.scaled[-index,]
# Y <- data.frame(GRNT.1=grnt[,1],
#                 GRNT.2=grnt[,2],
#                 GRNT.3=grnt[,3],
#                 GRNT.4=grnt[,4],
#                 GRNT.5=grnt[,5],
#                 GRNT.6=grnt[,6])
# Y.rng <- list(mins=apply(Y, 2, min), maxs=apply(Y, 2, max))
# Y.scaled <- as.data.frame(scale(Y, center=Y.rng[[1]], 
#                                 scale=Y.rng[[2]]-Y.rng[[1]]))
# Y.train <- Y.scaled[index,]
# Y.test <- Y.scaled[-index,]

# train neural network
mod <- mlp(X.train, Y, size=9, maxit=1000)

# combine and predict
fit.df <- tibble(Y1=c(as.matrix(Y)),
                 pred.m=c(as.matrix(mod$fitted.values)),
                 LC=rep(1:6, each=nrow(Y)),
                 Y2=c(as.matrix(cbind(X.train[,1:3], 
                                      X.train[,4]*X.train[,6],
                                      X.train[,4]*(1-X.train[,6]),
                                      X.train[,5]))),
                 Set="Y1+Y2") %>% 
  bind_rows(tibble(Y1=NA,
                pred.m=c(predict(mod, X.test)),
                LC=rep(1:6, each=nrow(X.test)),
                Y2=c(as.matrix(cbind(X.test[,1:3], 
                                     X.test[,4]*X.test[,6],
                                     X.test[,4]*(1-X.test[,6]),
                                     X.test[,5]))),
                Set="Y2"))

# plots
ggplot(filter(fit.df, Set=="Y1+Y2"), aes(x=Y2, y=Y1)) + geom_point(alpha=0.05) +
  xlim(0,1) + ylim(0,1) +
  geom_abline(slope=1, colour="red", linetype=2) + facet_grid(Set~LC)
ggplot(fit.df, aes(x=Y1, y=pred.m)) + geom_point(alpha=0.5) +
  xlim(0,1) + ylim(0,1) +
  geom_abline(slope=1, colour="red", linetype=2) + facet_grid(Set~LC)
ggplot(fit.df, aes(x=Y1, xend=Y1, y=Y2, yend=pred.m,
                      colour=abs(Y2-Y1)<abs(pred.m-Y1))) + 
  geom_abline(slope=1, linetype=3) + facet_grid(Set~LC) +
  scale_colour_manual(values=c("darkgreen", "red")) + xlim(0,1) + ylim(0,1) +
  geom_segment(arrow=arrow(length=unit(0.1, "cm")), alpha=0.4) + 
  labs(x="Y1", y="Y2 -> median") + theme(legend.position="none") 
ggplot(fit.df, aes(x=BlockCol, y=BlockRow, fill=Y2-Y1)) + geom_tile() +
  facet_wrap(~LC) + scale_fill_gradient2()

fit.df %>% group_by(Set, LC) %>%
  summarise(rmse.mod=(pred.m-Y1)^2 %>% mean %>% sqrt %>% round(3),
            rmse.Y2=(Y2-Y1)^2 %>% mean %>% sqrt %>% round(3),
            diff=rmse.mod-rmse.Y2, prop=(diff/rmse.Y2) %>% round(3))

```



